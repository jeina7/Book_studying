{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [PyTorch를 활용한 머신러닝, 딥러닝 철저 입문]\n",
    "## [Chapter 5-5] 예제: 와인 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#1. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#2. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Get Wine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names'])\n"
     ]
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "print(wine.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-2. Description of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(wine.DESCR[18:-1526])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#3. DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Create DataFrame in `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "173        0.61                  0.52             1.06              7.7  0.64   \n",
       "174        0.75                  0.43             1.41              7.3  0.70   \n",
       "175        0.69                  0.43             1.35             10.2  0.59   \n",
       "176        0.68                  0.53             1.46              9.3  0.60   \n",
       "177        0.76                  0.56             1.35              9.2  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "print(df.shape)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#4. Training / Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. Data Selecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`wine` 데이터에는 `class 0`, `class 1`, `class 2` 의 세 가지 데이터가 있지만, 이번 예제에서는 0과 1 두 가지 데이터만 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target[:130]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 178개의 데이터 중 index=130 까지의 데이터가 0과 1의 클래스를 가지는 데이터이므로, 이를 추출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 130)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data = wine.data[:130]\n",
    "wine_target = wine.target[:130]\n",
    "len(wine_data), len(wine_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. Mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 130개의 data에서 랜덤하게 추출할 index 역할을 하는 `mask` 리스트를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_test = int(len(wine_data) * 0.2)\n",
    "len_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_train = len(wine_data) - 26\n",
    "len_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "130개 중 20%의 데이터, 즉 26개의 데이터는 test data로, 나머지 104개의 데이터는 train data로 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  17,  18,  19,  20,  24,  25,  26,  28,  29,  30,  31,\n",
       "        32,  33,  35,  36,  37,  39,  40,  41,  42,  43,  44,  45,  46,\n",
       "        47,  49,  50,  51,  52,  53,  54,  55,  56,  57,  59,  60,  61,\n",
       "        62,  63,  65,  67,  68,  69,  70,  71,  72,  73,  74,  75,  77,\n",
       "        79,  80,  81,  82,  83,  84,  85,  88,  89,  90,  91,  93,  96,\n",
       "        97,  98, 100, 101, 103, 104, 105, 106, 107, 108, 110, 111, 112,\n",
       "       113, 114, 115, 116, 117, 119, 122, 124, 125, 126, 127, 128, 129])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (0, 178) 범위 내의 random index 추출\n",
    "mask_train = np.random.choice(len(wine_data), len_train, replace=False)\n",
    "mask_train.sort()\n",
    "print(len(mask_train))\n",
    "mask_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 15,  16,  21,  22,  23,  27,  34,  38,  48,  58,  64,  66,  76,\n",
       "        78,  86,  87,  92,  94,  95,  99, 102, 109, 118, 120, 121, 123])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (0, 178) 범위 내 중 trian 인덱스를 제외한 test index 추출\n",
    "mask_test = np.array(list(set(np.arange(len(wine_data))) - set(mask_train)))\n",
    "print(len(mask_test))\n",
    "mask_test.sort()\n",
    "mask_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3. Get Train / Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104, 104)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = wine.data[mask_train]\n",
    "train_y = wine.target[mask_train]\n",
    "len(train_X), len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = wine.data[mask_test]\n",
    "test_y = wine.target[mask_test]\n",
    "len(test_X), len(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-4. Get Train / Test data by `train_test_split`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 방법 외에, `train_test_split` 함수를 이용해 데이터를 분리할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 13) (104,)\n",
      "(26, 13) (26,)\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(wine_data, wine_target, test_size=0.2)\n",
    "\n",
    "print(train_X.shape, train_y.shape)\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#5. Make Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1. Transform Data Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 완성된 train, test 데이터를 PyTorch의 `tensor 데이터`로 변환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `torch.from_numpy(ndarray)` : numpy array를 torch tensor로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([104, 13]), torch.Size([104]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_X = torch.from_numpy(train_X).float()\n",
    "train_y = torch.from_numpy(train_y).long()\n",
    "\n",
    "# test data\n",
    "test_X = torch.from_numpy(test_X).float()\n",
    "test_y = torch.from_numpy(test_y).long()\n",
    "\n",
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train의 X와 y데이터를 `tensorDataset` 으로 합친다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `torch.utils.data.TensorDataset(data_tensor, target_tensor)` : 독립변수와 종속변수를 합쳐서 하나의 DataSet으로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 11.7900,   2.1300,   2.7800,  28.5000,  92.0000,   2.1300,   2.2400,\n",
       "           0.5800,   1.7600,   3.0000,   0.9700,   2.4400, 466.0000]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = TensorDataset(train_X, train_y)\n",
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2. Mini Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train 데이터를 미니배치로 학습시킬 수 있도록 16개 단위로 분할한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `torch.utils.data.DataLoader(dataset, batch_size=n, shuffle=True)` : DataSet을 원하는 크기의 mini batch로 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#6. Neural Network Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1. Neural Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.func1 = nn.Linear(13, 96)\n",
    "        self.func2 = nn.Linear(96, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 1층\n",
    "        x = self.func1(x)\n",
    "        # 1층 활성화함수\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # 2층\n",
    "        x = self.func2(x)\n",
    "        # 2층 활성화함수 (=출력함수)\n",
    "        y = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `torch.nn.Module` : 모든 신경망의 기본이 되는 클래스. 사용자가 정의하려는 클래스를 정의할 때 `nn.Module`을 상속받아 정의한다.  \n",
    "\n",
    "> `torch.nn.Linear(in_features, out_features, bias=True)` : 선형함수 ($ax+b$) 를 구현하는 layer  \n",
    "\n",
    "> `torch.nn.functional.relu(input)` : ReLu 함수  \n",
    "\n",
    "> `torch.nn.functional.log_softmax(input)` : log-softmax 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\# Jeina's comment\n",
    "\n",
    "#### 위의 신경망 구성에서, `forward` 함수의 출력함수 (2층 활성화함수)로 사용한 log_softmax 함수에 대해 발생한 issue    \n",
    "\n",
    "\n",
    "- 책에 나온 코드는 `y = F.log_softmax(x)` 로, `dim` 파라미터는 사용하지 않았다.\n",
    "\n",
    "\n",
    "- 그러나 이 코드를 그대로 실행하면 아래의 에러가 발생한다.\n",
    "```\n",
    "UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
    "```\n",
    "\n",
    "\n",
    "- `log_softmax` 함수의 `dim` 파라미터는 softmax 함수의 결과를 **어느 축을 기준으로 더해서 1이 되는 결과를 만들건지**를 결정한다.\n",
    "\n",
    "> - `dim=0` : column 기준 (axis=0) 으로 모든 값을 더하면 1\n",
    "- `dim=1` : row 기준 (axis=1) 으로 모든 값을 더하면 1\n",
    "\n",
    "- 현재 와인 분류 문제에서는 category class가 0과 1로, 두 가지 클래스를 분류하는 문제\n",
    "\n",
    "\n",
    "- 이 결과는 row 별로 결과가 출력되므로 (row의 길이가 2) `dim=1`이라는 파라미터를 추가했다.\n",
    "\n",
    "\n",
    "- [Reference | PyTorch Discuss](https://discuss.pytorch.org/t/implicit-dimension-choice-for-softmax-warning/12314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2. NN Instance 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (func1): Linear(in_features=13, out_features=96, bias=True)\n",
       "  (func2): Linear(in_features=96, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#7. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-1. Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `torch.nn.CrossEntropyLoss()` : 크로스 엔트로피 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-2. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `torch.optim.SGD(params, lr=eta)` : SGD (확률적 경사하강법) 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch \t total loss\n",
      "----- \t ----------------------\n",
      "50 \t 4.8501176834106445\n",
      "100 \t 4.8353095054626465\n",
      "150 \t 4.842362403869629\n",
      "200 \t 4.866007328033447\n",
      "250 \t 4.835178375244141\n",
      "300 \t 4.835207462310791\n"
     ]
    }
   ],
   "source": [
    "print(\"{} \\t {}\".format(\"epoch\", \"total loss\"))\n",
    "print(\"----- \\t ----------------------\")\n",
    "\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for train_X, train_y in train_loader:\n",
    "        \n",
    "        # 계산 그래프 구성\n",
    "        train_X, train_y = Variable(train_X), Variable(train_y)\n",
    "        \n",
    "        # gradient 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward 계산\n",
    "        output = model.forward(train_X)\n",
    "        \n",
    "        # loss 계산\n",
    "        loss = criterion(output, train_y)\n",
    "        \n",
    "        # 오차 역전파\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "        \n",
    "    # 50번째 epoch마다 loss 출력    \n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(\"{} \\t {}\".format(epoch+1, total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `torch.autograd.Variable(data)` : 텐서 래핑, 계산과정 기록  \n",
    "\n",
    "\n",
    "> `torch.autograd.backward(variables)` : gradient 역전파"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 조금씩 수렴하기는 하나, 데이터가 적은 관계로 크게 loss가 변화하지는 않는 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#8. Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8-1. test data 로 accuracy 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6153846153846154"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 그래프 구성\n",
    "test_X, test_y = Variable(test_X), Variable(test_y)\n",
    "\n",
    "# 결과를 0 또는 1이 되도록 변환\n",
    "result = torch.max(model(test_X).data, 1)[1]\n",
    "\n",
    "# test_y 와 결과가 같은 예측값의 개수 (맞춘 개수) 계산\n",
    "accuracy = sum(test_y.data.numpy() == result.numpy()) / len(test_y.data.numpy())\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도는 약 65.3% 정도로 확인"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
