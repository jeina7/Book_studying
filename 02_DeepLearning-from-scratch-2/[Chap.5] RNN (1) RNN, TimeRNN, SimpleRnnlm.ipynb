{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.np import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5. RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\# 5.3.1 RNN 계층 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 책에서는 단일 RNN 단위를 `RNN`으로, 각 RNN이 서로의 출력값을 다시 순환하면서 받는 T개의 RNN을 `Time RNN`으로 명명"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) 단일 RNN 클래스 구현\n",
    "- 단일 RNN 클래스는 시계열 데이터인 `x_t`를 처리하는 가중치 `Wx`와, 이전 층의 출력값인 `h_t`를 처리하는 가중치 `W_h` 두 가지를 가짐\n",
    "\n",
    "\n",
    "- $h_t = tanh(h_{t-1} W_h + x_t W_x + b)$ 의 식으로 `forward` 연산 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self, Wx, Wh, b):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.cache = None\n",
    "    \n",
    "    \n",
    "    def forward(self, x, h_prev):\n",
    "        Wx, Wh, b = self.params\n",
    "        t = np.matmul(h_prev, Wh) + np.matmul(x, Wx) + b\n",
    "        h_next = np.tanh(t)\n",
    "        \n",
    "        self.cache = (x, h_prev, h_next)\n",
    "        return h_next\n",
    "    \n",
    "    \n",
    "    def backward(self, dh_next):\n",
    "        Wx, Wh, b = self.params\n",
    "        x, h_prev, h_next = self.cache\n",
    "        \n",
    "        dt = dh_next * (1 - h_next ** 2)\n",
    "        db = np.sum(dt, axis=0)\n",
    "        dWh = np.matmul(h_prev.T, dt)\n",
    "        dh_prev = np.matmul(dt, Wh.T)\n",
    "        dWx = np.matmul(x.T, dt)\n",
    "        dx = np.matmul(dt, Wx.T)\n",
    "        \n",
    "        self.grads[0][...] = dWx\n",
    "        self.grads[1][...] = dWh\n",
    "        self.grads[2][...] = db\n",
    "        \n",
    "        return dx, dh_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) 단일 RNN이 모여있는 `Time RNN` 구현\n",
    "- `RNN`이 `T`개 모아서 한 계층인 `Time RNN`을 구현\n",
    "\n",
    "\n",
    "- `Time RNN`이라는 표현은 이 책의 독립적인 명명법임\n",
    "\n",
    "\n",
    "- `Time RNN`은 `stateful`이라는 변수를 가짐\n",
    "    - `stateful` : 이전 블록의 출력인 `h`를 저장할지 말지에 대한 참값 (stateful의 뜻: '상태가 있는')\n",
    "    - 즉, 이 값이 True이면 시계열 데이터가 아무리 길더라도 순전파를 끊지 않고 전파"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeRNN:\n",
    "    def __init__(self, Wx, Wh, b, stateful=False):\n",
    "        self.params = [Wx, Wh, b]\n",
    "        self.grads = [np.zeros_like(Wx), np.zeros_like(Wh), np.zeros_like(b)]\n",
    "        self.layers = None\n",
    "        self.h, self.dh = None, None\n",
    "        self.stateful = stateful\n",
    "        \n",
    "        \n",
    "    def forward(self, xs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, D = xs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        self.layers = []\n",
    "        hs = np.empty((N, T, H), dtype='f')\n",
    "        \n",
    "        # stateful=False이면 self.h를 영행렬로 저장\n",
    "        if not self.stateful or self.h is None:\n",
    "            self.h = np.zeros((N, H), dtype='f')\n",
    "            \n",
    "        for t in range(T):\n",
    "            layer = RNN(*self.params)\n",
    "            self.h = layer.forward(xs[:, t, :], self.h)\n",
    "            hs[:, t, :] = self.h\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        return hs\n",
    "    \n",
    "    \n",
    "    def backward(self, dhs):\n",
    "        Wx, Wh, b = self.params\n",
    "        N, T, H = dhs.shape\n",
    "        D, H = Wx.shape\n",
    "        \n",
    "        dxs = np.empty((N, T, D), dtype='f')\n",
    "        dh = 0\n",
    "        grads = [0, 0, 0]\n",
    "        for t in reversed(range(T)):\n",
    "            layer = self.layers[t]\n",
    "            dx, dh = layer.backward(dhs[:, t, :] + dh)\n",
    "            dxs[:, t, :] = dx\n",
    "            \n",
    "            # 가중치는 모든 단일 RNN의 가중치를 모두 더한 것\n",
    "            for i, grad in enumerate(layer.grads):\n",
    "                grads[i] += grad\n",
    "                \n",
    "        for i, grad in enumerate(grads):\n",
    "            self.grads[i][...] = grad\n",
    "        self.dh = dh\n",
    "        \n",
    "        return dxs\n",
    "    \n",
    "    \n",
    "    def set_state(self, h):\n",
    "        self.h = h\n",
    "    \n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.h = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## \\# 5.4.2 RNNLM 모델 - Time 계층 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RNN 언어 모델의 전체 구조인 `Time Embedding`, `Time RNN`, `Time Affine`, `Time Softmax` 를 모두 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) `Time Embedding` 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeEmbedding:\n",
    "    def __init__(self, W):\n",
    "        self.params = [W]\n",
    "        self.grads = [np.zeros_like(W)]\n",
    "        self.layers = None\n",
    "        self.W = W\n",
    "        \n",
    "    \n",
    "    def forward(self, xs):\n",
    "        N, T = xs.shape\n",
    "        V, D = self.W.shape\n",
    "        \n",
    "        out = np.empty((N, T, D), dtype='f')\n",
    "        self.layers = []\n",
    "        \n",
    "        for t in range(T):\n",
    "            layer = Embedding(self.W)\n",
    "            out[:, t, :] = layer.forward(xs[:, t])\n",
    "            self.layers.append(layer)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        N, T, D = dout.shape\n",
    "        \n",
    "        grad = 0\n",
    "        for t in range(T):\n",
    "            layer = self.layers[t]\n",
    "            layer.backward(dout[:, t, :])\n",
    "            grad += layer.grads[0]\n",
    "            \n",
    "        self.grads[0][...] = grad\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) `Time Affine` 계층\n",
    "- `TimeAffine`은 행렬 계산으로 효율적으로 처리하기 위해 `reshape` 해서 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeAffine:\n",
    "    def __init__(self, W, b):\n",
    "        self.params = [W, b]\n",
    "        self.grads = [np.zeros_like(W), np.zeros_like(b)]\n",
    "        self.x = None\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "        \n",
    "        rx = x.reshape(N*T, -1)\n",
    "        out = np.dot(rx, W) + b\n",
    "        self.x = x\n",
    "        return out.reshape(N, T, -1)\n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        x = self.x\n",
    "        N, T, D = x.shape\n",
    "        W, b = self.params\n",
    "        \n",
    "        dout = dout.reshape(N*T, -1)\n",
    "        rx = x.reshape(N*T, -1)\n",
    "        \n",
    "        db = np.sum(dout, axis=0)\n",
    "        dW = np.dot(rx.T, dout)\n",
    "        dx = np.dot(dout, W.T)\n",
    "        dx = dx.reshape(*x.shape)\n",
    "        \n",
    "        self.grads[0][...] = dW\n",
    "        self.grads[1][...] = db\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) `Time Softmax With Loss` 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [], []\n",
    "        self.cache = None\n",
    "        self.ignore_label = -1\n",
    "        \n",
    "    \n",
    "    def forward(self, xs, ts):\n",
    "        N, T, V = xs.shape\n",
    "        \n",
    "        if ts.ndim == 3:\n",
    "            ts = ts.argmax(axis=2)\n",
    "            \n",
    "        # ignore_label이 -1 인 것들을 마스킹 (ignore_label 위치에는 0으로 저장됨)\n",
    "        mask = (ts != self.ignore_label)\n",
    "        \n",
    "        xs = xs.reshape(N * T, V)\n",
    "        ts = ts.reshape(N * T)\n",
    "        mask = mask.reshape(N * T)\n",
    "        \n",
    "        ys = softmax(xs)\n",
    "        ls = np.log(ys[np.arange(N * T), ts])\n",
    "        ls *= mask # ignore_label 위치는 loss를 0으로 계산\n",
    "        loss = -np.sum(ls)\n",
    "        loss /= mask.sum()\n",
    "        \n",
    "        self.cache = (ts, ys, mask, (N, T, V))\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        ts, ys, mask, (N, T, V) = self.cache\n",
    "        \n",
    "        dx = ys\n",
    "        dx[np.arange(N * T), ts] -= 1\n",
    "        dx *= dout\n",
    "        dx /= mask.sum()\n",
    "        dx *= mask[:, np.newaxis]\n",
    "        \n",
    "        dx = dx.reshape((N, T, V))\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## \\# 5.5.1 `SimpleRnnlm` 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRnnlm:\n",
    "    def __init__(self, vocab_size, wordvec_size, hidden_size):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        # 가중치 초기화 : Xavier 초깃값 \n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        rnn_Wx = (rn(D, H) / np.sqrt(D)).astype('f')\n",
    "        rnn_Wh = (rn(H, H) / np.sqrt(H)).astype('f')\n",
    "        rnn_b = np.zeros(H).astype('f')\n",
    "        affine_W = (rn(H, V) / np.sqrt(H)).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        # 계층 생성\n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeRNN(rnn_Wx, rnn_Wh, rnn_b, stateful=True),\n",
    "            TimeAffine(affine_W, affine_b)\n",
    "        ]\n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.rnn_layer = self.layers[1]\n",
    "        \n",
    "        # 모든 가중치와 기울기 모으기\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "            \n",
    "    def forward(self, xs, ts):\n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        loss = self.loss_layer.forward(xs, ts)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.rnn_layer.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## \\# 5.5.2 언어 모델의 평가 - `SimpleRnnlm` 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 혼잡도(perplexity)를 이용해서 평가\n",
    "\n",
    "\n",
    "- perplexity란, 확률의 역수 값으로 잘 예측(확률이 높음)할 수록 값이 낮고, 잘 못 예측(확률이 낮음)할 수록 값이 높다\n",
    "- 즉, perplexity는 낮을수록 덜 혼잡하므로, 더 좋은 예측을 한다고 할 수 있음\n",
    "\n",
    "\n",
    "- 여기서, perplexity 값은 '분기수'(number of branches) 라고 생각할 수 있다. \n",
    "- 즉, `perplexity = 1.25`면 예측하는 단어 수가 약 1.25개 정도인데, `perplexity = 5`면 예측하는 단어 수가 5개나 된다는 의미.\n",
    "- 확률값이 1이면 perplexity도 1이므로, 단 하나의 단어로 좁혀졌다는 뜻으로 볼 수 있음. \n",
    "\n",
    "\n",
    "- 데이터가 여러 개일때는, $perplexity = e^L$ (L은 손실함수값) 으로 둘 수 있음 (교차엔트로피오차 사용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## \\# 5.5.3 RNNLM의 학습코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SimpleRnnlm은 PTB 데이터셋 전체를 학습할 수 없으므로, 첫 1000단어만 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from common.optimizer import SGD\n",
    "from common.dataset import PTB\n",
    "from common.layer import Embedding\n",
    "from common.function import softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "wordvec_size = 100\n",
    "hidden_size = 100\n",
    "time_size = 5 # Truncated BPTT 블록 안의 RNN 개수\n",
    "lr = 0.1\n",
    "max_epoch = 100\n",
    "log_step = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 학습 데이터 가져오기 (첫 1000단어만)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptb = PTB()\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_size = 1000\n",
    "corpus = corpus[:corpus_size]\n",
    "vocab_size = int(max(corpus) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 입력데이터: 첫 999단어 / 정답데이터: 첫단어 빼고 999단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus size: 1000, vocab size: 418\n"
     ]
    }
   ],
   "source": [
    "data_size = len(xs)\n",
    "print(\"corpus size: %d, vocab size: %d\" % (corpus_size, vocab_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. 학습에 사용되는 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = data_size // (batch_size * time_size)\n",
    "time_idx = 0    # time_idx는 한 블록 안에서 몇 번째인지 나타내는 idx (offset + time_idx)\n",
    "total_loss = 0\n",
    "loss_count = 0\n",
    "ppl_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleRnnlm(vocab_size, wordvec_size, hidden_size)\n",
    "optimizer = SGD(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 각 미니배치에서 샘플을 읽을 위치를 계산 (offset)\n",
    "- offset은 데이터를 읽을 시작 위치로 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jump = (corpus_size - 1) // batch_size\n",
    "offsets = [i * jump for i in range(batch_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 | ppl : 403.15 \n",
      "epoch 11 | ppl : 188.91 \n",
      "epoch 21 | ppl : 181.32 \n",
      "epoch 31 | ppl : 156.67 \n",
      "epoch 41 | ppl : 115.89 \n",
      "epoch 51 | ppl : 71.71 \n",
      "epoch 61 | ppl : 40.75 \n",
      "epoch 71 | ppl : 22.93 \n",
      "epoch 81 | ppl : 13.65 \n",
      "epoch 91 | ppl : 7.52 \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    for iter in range(max_iters):\n",
    "        batch_x = np.empty((batch_size, time_size), dtype='i')\n",
    "        batch_t = np.empty((batch_size, time_size), dtype='i')\n",
    "        for t in range(time_size):\n",
    "            for i, offset in enumerate(offsets):\n",
    "                batch_x[i, t] = xs[(offset + time_idx) % data_size]\n",
    "                batch_t[i, t] = ts[(offset + time_idx) % data_size]\n",
    "            time_idx += 1\n",
    "            \n",
    "        loss = model.forward(batch_x, batch_t)\n",
    "        model.backward()\n",
    "        optimizer.update(model.params, model.grads)\n",
    "        total_loss += loss\n",
    "        loss_count += 1\n",
    "        \n",
    "    avg_loss = total_loss / loss_count\n",
    "    ppl = np.exp(avg_loss)\n",
    "    if (epoch) % log_step == 0:\n",
    "        print(\"epoch %d | ppl : %.2f \" % (epoch+1, ppl))\n",
    "    ppl_list.append(float(ppl))\n",
    "    total_loss, loss_count = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ppl_list)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
