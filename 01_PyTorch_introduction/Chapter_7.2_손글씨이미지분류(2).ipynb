{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [PyTorch를 활용한 머신러닝, 딥러닝 철저 입문]\n",
    "## [Chapter 7-2] 예제: 손글씨 이미지 분류 (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#1. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets, model_selection\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#2. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-1. Get MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'details', 'categories', 'url'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = datasets.fetch_openml('mnist_784', data_home='./data')\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mnist data 의 X (feature) 를 255로 정규화 해서 변수에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_data = mnist.data / 255\n",
    "mnist_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mnist data의 y (label)을 변수에 저장\n",
    "- mnist data가 업데이트 되면서, label의 target value들이 모두 `string` type의 데이터가 되었으므로 `int`로 형변환을 해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_label = mnist.target\n",
    "mnist_label = mnist_label.astype(int)\n",
    "print(mnist_label.shape)\n",
    "mnist_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#3. Training / Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-1. Get Train / Test data by `train_test_split`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train data는 70000개의 데이터 중 5000개, test data는 500개를 추출하기로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784) (5000,)\n",
      "(500, 784) (500,)\n"
     ]
    }
   ],
   "source": [
    "train_size = 5000\n",
    "test_size = 500\n",
    "\n",
    "train_X, test_X, train_y, test_y = model_selection.train_test_split(mnist_data, mnist_label, \\\n",
    "                                                                    train_size = train_size, test_size=test_size)\n",
    "\n",
    "print(train_X.shape, train_y.shape)\n",
    "print(test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-2. 2D Array for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape: (Data nums, channel nums, height, width)\n",
    "train_X = train_X.reshape(len(train_X), 1, 28, 28)\n",
    "test_X = test_X.reshape(len(test_X), 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#4. Make Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. Transform Data Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 완성된 train, test 데이터를 PyTorch의 `tensor 데이터`로 변환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5000, 1, 28, 28]), torch.Size([5000]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train data\n",
    "train_X = torch.from_numpy(train_X).float()\n",
    "train_y = torch.from_numpy(train_y).long()\n",
    "\n",
    "# test data\n",
    "test_X = torch.from_numpy(test_X).float()\n",
    "test_y = torch.from_numpy(test_y).long()\n",
    "\n",
    "train_X.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train의 X와 y데이터를 `tensorDataset` 으로 합친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), tensor(2))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = TensorDataset(train_X, train_y)\n",
    "train[0][0].shape, train[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train의 각 element들은 feature와 label의 쌍으로 이루어져있음을 확인\n",
    "- 첫 번째 쌍은 `28 x 28`의 2차원 텐서와, `2`라는 label의 쌍으로 이루어져 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. Mini Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train 데이터를 미니배치로 학습시킬 수 있도록 100개 단위로 분할한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#5. Neural Network Composition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-1. Neural Network class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # 합성곱층\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) #(입력 채널 수, 출력 채널 수, 필터크기)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        \n",
    "        # 완전연결층\n",
    "        # 입력노드수 : ((28-5+1) / 2) -5+1) / 2\n",
    "        self.func1 = nn.Linear(256, 64)\n",
    "        self.func2 = nn.Linear(64, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 입력층 - 합성곱1층\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # 풀링1층\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # 합성곱2층\n",
    "        x = F.relu(self.conv2(x))\n",
    "        # 풀링2층\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        # len = 256의 1차원 텐서로 풀어주기\n",
    "        x = x.view(-1, 256)\n",
    "        \n",
    "        # 완전연결층\n",
    "        x = F.relu(self.func1(x))\n",
    "        \n",
    "        # 출력층\n",
    "        x = self.func2(x)\n",
    "        # 출력층 활성화함수 : log_softmax\n",
    "        y = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-2. NN Instance 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (func1): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (func2): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱이 두 층 있고, 완전연결층과 출력층까지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#6. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-1. Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-2. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch \t total loss\n",
      "----- \t ----------------------\n",
      "100 \t 4.132058143615723\n",
      "200 \t 0.9005931615829468\n",
      "300 \t 0.277071088552475\n",
      "400 \t 0.11689137667417526\n",
      "500 \t 0.06956642121076584\n",
      "600 \t 0.047022223472595215\n",
      "700 \t 0.03501998633146286\n",
      "800 \t 0.02728416956961155\n",
      "900 \t 0.022063668817281723\n",
      "1000 \t 0.018530182540416718\n",
      "CPU times: user 16min 27s, sys: 6min 22s, total: 22min 49s\n",
      "Wall time: 15min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"{} \\t {}\".format(\"epoch\", \"total loss\"))\n",
    "print(\"----- \\t ----------------------\")\n",
    "\n",
    "for epoch in range(1000):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for train_X, train_y in train_loader:\n",
    "        \n",
    "        # 계산 그래프 구성\n",
    "        train_X, train_y = Variable(train_X), Variable(train_y)\n",
    "        \n",
    "        # gradient 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward 계산\n",
    "        output = model.forward(train_X)\n",
    "        \n",
    "        # loss 계산\n",
    "        loss = criterion(output, train_y)\n",
    "        \n",
    "        # 오차 역전파\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "        \n",
    "    # 50번째 epoch마다 loss 출력    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(\"{} \\t {}\".format(epoch+1, total_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 16분이나 걸렸다.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 다음은 손글씨 이미지 분류 (1)의 결과다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chapter 6.3 손글씨이미지 분류 (1)\n",
    "```\n",
    "epoch \t total loss\n",
    "----- \t ----------------------\n",
    "100   \t 34.955047607421875\n",
    "200 \t   4.097681999206543\n",
    "300 \t   0.3379775285720825\n",
    "400 \t   0.14065010845661163\n",
    "500 \t   0.060440998524427414\n",
    "600 \t   0.0877748653292656\n",
    "700 \t   0.04214557260274887\n",
    "800 \t   0.04590927064418793\n",
    "900 \t   0.035796478390693665\n",
    "1000 \t  0.019102295860648155  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최종적인 loss값은 크게 차이 나지 않는 것 같으나.. 초기 loss는 확연히 작았음을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \\#7. Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-1. test data 로 accuracy 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 그래프 구성\n",
    "test_X, test_y = Variable(test_X), Variable(test_y)\n",
    "\n",
    "# 결과를 0 또는 1이 되도록 변환\n",
    "result = torch.max(model(test_X).data, 1)[1]\n",
    "\n",
    "# test_y 와 결과가 같은 예측값의 개수 (맞춘 개수) 계산\n",
    "accuracy = sum(test_y.data.numpy() == result.numpy()) / len(test_y.data.numpy())\n",
    "\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "92.6%의 정확도에 그쳤던 손글씨이미지분류(1)에서보다 약 4% 올랐음을 확인!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
